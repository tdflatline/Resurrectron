# Config file for all modules.

# Config settings for soul creation (extract.py)
[soul]
# Attempt AGFL usage. If false, will only use nltk.pos_tag.
attempt_agfl = True

# If using AGFL, reject sentences that AGFL produces no tags for.
# Setting this to false may make your output noisier. However, it
# may also help you capture certain idioms and odd phrases.
reject_agfl_failures = True

# Fall back to nltk.pos_tag when AGFL doesn't fully tag a sentence.
# If set to false, your resulting output will be better, but this
# may come at the expense of certain types of expressions. Set to
# false if you have a large body of text to work with and correctness
# is important.
agfl_nltk_fallback = True

# If true, summarize .posts down as opposed to taking consecutive
# sentences of <= 140 chars.
post_summarize = False

# Number of sentences to use in a summarized post
post_summarize_len = 5

# Split each post into phrases of this length (summarized or not).
# This should match brain.tweet_len below.
post_len = 140

# Gzip-compress the resulting soul file.
gzip_soul = True

# Log level for soul generation
soul_log_level = "INFO"

# Config settings for brain creation (resurrect.py)
[brain]
# Tag context for the state-labels of the HMM. 4 seems to be a good
# balance between speed and grammar. Higher numbers will produce better
# grammar at the expense of taking a longer time to fill the tweet pool
# due to a higher tendnecy to generate tweets that are very similar to
# ones on the soul corpus (see max_shared_word_ratio below). Having
# a very large corpus may help counteract this, due to larger vocab size
# for the HMM.
hmm_context = 4

# Offset into the tag context for the current term. For example:
# context=4,offset=1 gives state labels of (tag,current_tag,tag,tag)
hmm_offset = 1

# If a generated tweet shares more than this fraction of words with any
# already generated tweet, or with any tweet in the soul corpus, it is
# rejected. Setting this too low will cause tweet pool generation to
# take a really long time.
max_shared_word_ratio = 0.75

# The AI has contextual memory for each person that sends it a message.
# It also remembers the most recent thing it said when it recieves an @msg.
# The way this works is via a TF-IDF score vector. This constant governs
# how fast it "forgets" this score vector. The closer to 1.0, the shorter
# the memory.
memory_decay_rate = 0.25

# Max length for each tweet/response (should match soul.post_len above)
tweet_len = 140

# If this is non-zero, the tweet pool will have a number of messages
# equal to this multiple of the tagged soul corpus.
tweet_pool_multiplier = 2.0

# The maximum size of the tweet pool. If tweet_pool_multiplier is set,
# this value will act as a cap on that value. Otherwise, it acts as the
# total number of tweets to generate. Note that we require approx 300MB
# of memory for every 1000 tweets in the tweet pool.
tweet_pool_max = 5000

# How many new tweets before we save the .brain file when generating tweets
save_brain_every = 100

# gzip the brain file.
gzip_brain = True

# Min @msg reply score. Messages with a TF-IDF score less than this
# won't recieve a reply.
min_msg_reply_score = 0.333

# min follow reply score
min_follow_reply_score = 0.666

# Log level for brain generation
brain_log_level = "INFO"

# Config settings for body
[body]
